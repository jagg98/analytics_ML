{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # regresión logística -- Aprendizaje supervisado\n",
    " \n",
    " La primera técnica de aprendizaje supervisado que se desarrolla generalmente es la regresión logística debido a su sencillez.\n",
    " \n",
    " La regresión logística consiste en la maximización de la función de verosimilitud ($P(y = 1, y = 0 | \\mathbf{x}, \\mathbf{W})$) o en la minimización del error cuadrático medio entre la etiquetas de entrenamiento ($\\mathbf{t}$) y la función sigmoide (respuesta del sistema), $\\phi\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementación\n",
    "\n",
    "Con el fin de probar la implementación del algoritmo, utilizaremos la base de datos *iris*, que consta de tres clases(*Iris setosa*,*Iris versicolor*,*Iris virgencia*), 50 observaciones por clase y 4 características por observación: ancho y largo del petalo, ancho y largo del sépalo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primero importamos las librerias que necesitamos\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression #Librería para regresión logística\n",
    "#logística\n",
    "#Librería para la partición de la base de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "#librería para cargar la base de datos iris\n",
    "from sklearn import datasets\n",
    "#librería para el procesamiento\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "#Primero cargamos la base de datos iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data # en X guardamos la matriz de observaciones\n",
    "y = iris.target # guardamos las etiquetas\n",
    "\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4) (45, 4)\n",
      "(105,) (45,)\n"
     ]
    }
   ],
   "source": [
    "#particionamos la base de datos en entrenaminto y validacion\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "**Ejercicio 1**\n",
    "Aplica la función de preprocesamiento requerida para normalizar los datos sobre la media y desviación estandar, i.e. $\\mu = 0$,\n",
    "$\\test{std} = 1$. Debes usar los códigos implementados en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remocion(X_train, X_test):\n",
    "    media = X_train.mean(axis = 0) #calcula un vector de medias por columna\n",
    "    #o sea por caracteristicas. Debe ser de tamaño p\n",
    "    X_train = X_train - media #hace la operación para cada fila\n",
    "    desviacion = X_train.std(axis = 0) #calcula la desviación estándar\n",
    "    X_train = X_train/desviacion #hacemos la división sobre la desviación\n",
    "    #realizamos la misma operación sobre el X_test con los datos del x_train\n",
    "    return X_train, X_test #retornamos las dos matrices preprocesadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.47844073e-15 -4.61006894e-16 -6.89395631e-16  1.05735526e-17]\n",
      "[0.87268242 0.43925932 1.79595918 0.77637684]\n"
     ]
    }
   ],
   "source": [
    "X_train_prepro, X_test_prepro = remocion(X_train, X_test)\n",
    "print(X_train_prepro.mean(axis = 0))\n",
    "print(X_train_prepro.std(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=0,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entrenamos el clasificador primero instanciamos el clasificador\n",
    "clasificador = LogisticRegression(C = 1000.0, random_state = 0)\n",
    "#Donde C es un parámetro regularización\n",
    "#entrenamos el clasificador\n",
    "clasificador.fit(X_train_prepro, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "#realizamos el test o validación\n",
    "y_pred = clasificador.predict(X_test_prepro)\n",
    "# En el y_pred obtengo las etiquetas que el clasificador encontró\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3**\n",
    "\n",
    "Realizar el procedimiento anterior para el procesamiento denominado *escalamiento*, comparar el porcentaje de acierto del clasificador par ambos preprocesamientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalamiento(X_train, X_test):\n",
    "    maximo = X_train.max(axis = 0) #Calculamos el máximo del train\n",
    "    minimo = X_train.min(axis = 0) #Calculamos el mínimo del train\n",
    "    X_train_prepro = (X_train - minimo)/(maximo - minimo) # aplicamos la fórmula\n",
    "    X_test_prepro = (X_test - minimo)/(maximo - minimo) #Sobre ambos conjuntos\n",
    "    return X_train_prepro, X_test_prepro #devolvemos los conjuntos procesados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44259259 0.43531746 0.47044335 0.46984127]\n",
      "[0.24241178 0.18302472 0.30964814 0.32349035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=0,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepro, X_test_prepro = escalamiento(X_train, X_test)\n",
    "print(X_train_prepro.mean(axis = 0))\n",
    "print(X_train_prepro.std(axis = 0))\n",
    "clasificador.fit(X_train_prepro, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "#realizamos el test o validación\n",
    "y_pred = clasificador.predict(X_test_prepro)\n",
    "# En el y_pred obtengo las etiquetas que el clasificador encontró\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0]\n",
      "2.2222222222222223\n",
      "97.77777777777777\n"
     ]
    }
   ],
   "source": [
    "error = np.mean(y_test != y_pred)\n",
    "print(y_pred)\n",
    "print(error*100)\n",
    "acierto = np.mean(y_test == y_pred)\n",
    "print(acierto*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
